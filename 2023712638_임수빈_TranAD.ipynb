{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seonjing/Advanced_Machine_Learning_8team/blob/main/2023712638_%EC%9E%84%EC%88%98%EB%B9%88_TranAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dqz9ag46twSq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Transformer 기반 TranAD 모델 정의\n",
        "class TranAD(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=2):\n",
        "        super(TranAD, self).__init__()\n",
        "        self.encoder = nn.Transformer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dim_feedforward=128,\n",
        "            dropout=0.1,\n",
        "            activation='relu'\n",
        "        )\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "        self.output_projection = nn.Linear(d_model, input_dim)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        # 입력 데이터 차원 변환\n",
        "        src = self.input_projection(src).permute(1, 0, 2)  # (batch, seq_len, dim) -> (seq_len, batch, dim)\n",
        "        tgt = self.input_projection(tgt).permute(1, 0, 2)  # 동일 차원 변환\n",
        "        output = self.encoder(src, tgt)  # Transformer에 src와 tgt를 전달\n",
        "        output = output.permute(1, 0, 2)  # 복원 (seq_len, batch, dim) -> (batch, seq_len, dim)\n",
        "        output = self.output_projection(output)  # 차원 변환\n",
        "        return output\n",
        "\n",
        "# 이상 점수 계산 함수\n",
        "def calculate_anomaly_score(original, reconstructed):\n",
        "    return torch.mean((original - reconstructed) ** 2, dim=-1)\n",
        "\n",
        "# 데이터 전처리 함수\n",
        "def preprocess_data(data, window_size):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - window_size):\n",
        "        sequences.append(data[i:i+window_size])\n",
        "    return np.array(sequences)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-hPufhttwSu",
        "outputId": "8fc68daa-3721-454d-b00d-fea17bdfd52a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/beenee/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n",
            "/Users/beenee/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "\n",
        "# KaggleHub로 데이터셋 다운로드\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"boltzmannbrain/nab\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# 데이터 파일 경로 확인\n",
        "dataset_file = os.path.join(\"/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWdkwobntwSv",
        "outputId": "e0551aa6-2012-4299-be09-3f2721e5fa13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available CSV files:\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_825cc2.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_network_in_257a54.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_c6585a.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/rds_cpu_utilization_cc0c53.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_5f5533.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_disk_write_bytes_c0d644.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/rds_cpu_utilization_e47b3b.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_network_in_5abac7.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_ac20cd.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/elb_request_count_8c0756.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_24ae8d.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_disk_write_bytes_1ef3de.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/iio_us-east-1_i-a2eb1cd9_NetworkIn.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_53ea38.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_77c1ca.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/grok_asg_anomaly.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAWSCloudwatch/realAWSCloudwatch/ec2_cpu_utilization_fe7f93.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTraffic/realTraffic/speed_7578.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTraffic/realTraffic/TravelTime_387.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTraffic/realTraffic/TravelTime_451.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTraffic/realTraffic/speed_6005.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTraffic/realTraffic/occupancy_t4013.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTraffic/realTraffic/occupancy_6005.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTraffic/realTraffic/speed_t4013.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTraffic/__MACOSX/realTraffic/._occupancy_6005.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTraffic/__MACOSX/realTraffic/._speed_6005.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialWithAnomaly/artificialWithAnomaly/art_daily_flatmiddle.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialWithAnomaly/artificialWithAnomaly/art_daily_jumpsdown.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialWithAnomaly/artificialWithAnomaly/art_daily_jumpsup.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialWithAnomaly/artificialWithAnomaly/art_load_balancer_spikes.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialWithAnomaly/artificialWithAnomaly/art_increase_spike_density.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialWithAnomaly/artificialWithAnomaly/art_daily_nojump.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAdExchange/realAdExchange/exchange-3_cpm_results.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAdExchange/realAdExchange/exchange-4_cpm_results.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAdExchange/realAdExchange/exchange-2_cpm_results.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAdExchange/realAdExchange/exchange-2_cpc_results.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAdExchange/realAdExchange/exchange-4_cpc_results.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realAdExchange/realAdExchange/exchange-3_cpc_results.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialNoAnomaly/artificialNoAnomaly/art_daily_small_noise.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialNoAnomaly/artificialNoAnomaly/art_daily_perfect_square_wave.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialNoAnomaly/artificialNoAnomaly/art_noisy.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialNoAnomaly/artificialNoAnomaly/art_flatline.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/artificialNoAnomaly/artificialNoAnomaly/art_daily_no_noise.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_AAPL.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_UPS.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_KO.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_GOOG.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_CVS.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_FB.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_IBM.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_CRM.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_PFE.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets/Twitter_volume_AMZN.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realKnownCause/realKnownCause/ambient_temperature_system_failure.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realKnownCause/realKnownCause/machine_temperature_system_failure.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realKnownCause/realKnownCause/ec2_request_latency_system_failure.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realKnownCause/realKnownCause/rogue_agent_key_updown.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realKnownCause/realKnownCause/nyc_taxi.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realKnownCause/realKnownCause/cpu_utilization_asg_misconfiguration.csv\n",
            "/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realKnownCause/realKnownCause/rogue_agent_key_hold.csv\n"
          ]
        }
      ],
      "source": [
        "csv_files = []\n",
        "for root, dirs, files in os.walk(path):\n",
        "    for file in files:\n",
        "        if file.endswith(\".csv\"):\n",
        "            csv_files.append(os.path.join(root, file))\n",
        "\n",
        "print(\"Available CSV files:\")\n",
        "for csv_file in csv_files:\n",
        "    print(csv_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gEXVK90twSv",
        "outputId": "7751276c-0eb0-4e98-cb0c-e4030028cbcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1\n",
            "             timestamp  value\n",
            "0  2015-02-26 21:42:53     35\n",
            "1  2015-02-26 21:47:53     41\n",
            "2  2015-02-26 21:52:53     32\n",
            "3  2015-02-26 21:57:53     36\n",
            "4  2015-02-26 22:02:53     32\n",
            "Train data size: 12665\n",
            "Test data size: 3167\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "\n",
        "# KaggleHub로 데이터셋 다운로드\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"boltzmannbrain/nab\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# 데이터 파일 경로 확인\n",
        "dataset_file = os.path.join(path, \"realTweets\",\"realTweets\", \"Twitter_volume_GOOG.csv\")\n",
        "\n",
        "# 데이터 로드\n",
        "data = pd.read_csv(dataset_file)\n",
        "print(data.head())\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data['value'].values.reshape(-1, 1))\n",
        "\n",
        "# 시계열 윈도우 생성\n",
        "def preprocess_data(data, window_size):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - window_size):\n",
        "        sequences.append(data[i:i+window_size])\n",
        "    return np.array(sequences)\n",
        "\n",
        "window_size = 10\n",
        "sequences = preprocess_data(scaled_data, window_size)\n",
        "\n",
        "# Train/Test Split\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(sequences) * split_ratio)\n",
        "train_data = sequences[:split_index]\n",
        "test_data = sequences[split_index:]\n",
        "\n",
        "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
        "\n",
        "# train_data와 test_data의 개수 확인하기\n",
        "train_data_size = train_data.shape[0]\n",
        "test_data_size = test_data.shape[0]\n",
        "\n",
        "print(f\"Train data size: {train_data_size}\")\n",
        "print(f\"Test data size: {test_data_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJi8EWX2twSw",
        "outputId": "04d49105-8d15-4bc7-c9a3-9085bc83c0a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset directory structure: ['Twitter_volume_AAPL.csv', 'Twitter_volume_UPS.csv', 'Twitter_volume_KO.csv', 'Twitter_volume_GOOG.csv', 'Twitter_volume_CVS.csv', 'Twitter_volume_FB.csv', 'Twitter_volume_IBM.csv', 'Twitter_volume_CRM.csv', 'Twitter_volume_PFE.csv', 'Twitter_volume_AMZN.csv']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# 경로 확인\n",
        "dataset_path = '/Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1/realTweets/realTweets'\n",
        "print(\"Dataset directory structure:\", os.listdir(dataset_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNQRue3MtwSw",
        "outputId": "75df1100-5c61-4915-cba9-750c83400088"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /Users/beenee/.cache/kagglehub/datasets/boltzmannbrain/nab/versions/1\n",
            "Train data size: 12665\n",
            "Test data size: 3167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/beenee/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.0000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/beenee/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# KaggleHub로 데이터셋 다운로드\n",
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"boltzmannbrain/nab\")\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "# 데이터 파일 경로 확인\n",
        "dataset_file = os.path.join(path, \"realTweets\", \"realTweets\", 'Twitter_volume_GOOG.csv')\n",
        "data = pd.read_csv(dataset_file)\n",
        "\n",
        "# 데이터 스케일링\n",
        "scaler = MinMaxScaler()\n",
        "scaled_data = scaler.fit_transform(data['value'].values.reshape(-1, 1))\n",
        "\n",
        "# 시계열 윈도우 생성\n",
        "def preprocess_data(data, window_size):\n",
        "    sequences = []\n",
        "    for i in range(len(data) - window_size):\n",
        "        sequences.append(data[i:i+window_size])\n",
        "    return np.array(sequences)\n",
        "\n",
        "window_size = 10\n",
        "sequences = preprocess_data(scaled_data, window_size)\n",
        "\n",
        "# Train/Test Split\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(sequences) * split_ratio)\n",
        "train_data = sequences[:split_index]\n",
        "test_data = sequences[split_index:]\n",
        "\n",
        "train_data = torch.tensor(train_data, dtype=torch.float32)\n",
        "test_data = torch.tensor(test_data, dtype=torch.float32)\n",
        "\n",
        "\n",
        "# train_data와 test_data의 개수 확인하기\n",
        "train_data_size = train_data.shape[0]\n",
        "test_data_size = test_data.shape[0]\n",
        "\n",
        "print(f\"Train data size: {train_data_size}\")\n",
        "print(f\"Test data size: {test_data_size}\")\n",
        "\n",
        "\n",
        "# TranAD 모델 정의 (Transformer 기반 모델)\n",
        "class TranADModel(nn.Module):\n",
        "    def __init__(self, input_dim, model_dim, num_heads, num_layers):\n",
        "        super(TranADModel, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, model_dim)\n",
        "        self.encoder = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=model_dim, nhead=num_heads),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.output_projection = nn.Linear(model_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_projection(x)\n",
        "        x = self.encoder(x)\n",
        "        x = self.output_projection(x)\n",
        "        return x\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = 1\n",
        "model_dim = 64\n",
        "num_heads = 8\n",
        "num_layers = 4\n",
        "model = TranADModel(input_dim=input_dim, model_dim=model_dim, num_heads=num_heads, num_layers=num_layers)\n",
        "\n",
        "# 이상 점수 계산 함수\n",
        "def calculate_anomaly_score(original, reconstructed):\n",
        "    return torch.mean((original - reconstructed) ** 2).item()\n",
        "\n",
        "# 이상 레이블 생성 (임계값을 기준으로 수동으로 레이블링)\n",
        "threshold = 0.6  # 예시: 임계값 0.6 초과인 경우 이상으로 간주\n",
        "true_labels = [1 if value > threshold else 0 for value in data['value']]\n",
        "\n",
        "# test_data에 맞는 true_labels 생성 (test_data 크기에 맞춰야 함)\n",
        "test_true_labels = true_labels[-len(test_data):]\n",
        "\n",
        "# 모델 평가\n",
        "model.eval()\n",
        "anomaly_scores = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for sequence in test_data:\n",
        "        sequence = sequence.unsqueeze(0)  # 배치 차원 추가\n",
        "        reconstructed = model(sequence)\n",
        "        score = calculate_anomaly_score(sequence, reconstructed)\n",
        "        anomaly_scores.append(score)\n",
        "\n",
        "# 이상 점수 시각화\n",
        "plt.plot(anomaly_scores, label='Anomaly Score')\n",
        "plt.title(\"Anomaly Detection Scores\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# F1, Precision, Recall, AUC 계산\n",
        "# 임계값을 기준으로 탐지된 이상 여부를 결정\n",
        "detected_anomalies = [1 if score > 0.1 else 0 for score in anomaly_scores]  # threshold 값 조정\n",
        "\n",
        "from sklearn.metrics import f1_score, average_precision_score, precision_recall_curve\n",
        "f1 = f1_score(test_true_labels, detected_anomalies)\n",
        "precision = precision_score(test_true_labels, detected_anomalies)\n",
        "recall = recall_score(test_true_labels, detected_anomalies)\n",
        "pr_auc = average_precision_score(test_true_labels, anomaly_scores)\n",
        "\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vCvjQYptwSx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "# 데이터 경로 설정\n",
        "dataset_path = \"/Users/beenee/Downloads/realKnownCause\"  # 데이터셋 폴더 경로\n",
        "label_file = os.path.join(dataset_path, \"labels.json\")  # 레이블 파일 경로"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsep8UmAtwSx"
      },
      "source": [
        "## 논문 성능 구현"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NRJovTftwSy"
      },
      "source": [
        "#### 1) 논문 제시 파라미터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9XBqIQPtwSy",
        "outputId": "6c5bb7db-22ea-45ff-bc95-204f407f9746"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size: 12665\n",
            "Test data size: 3167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/beenee/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25, Loss: 0.005377\n",
            "Epoch 2/25, Loss: 0.000160\n",
            "Epoch 3/25, Loss: 0.000076\n",
            "Epoch 4/25, Loss: 0.000054\n",
            "Epoch 5/25, Loss: 0.000059\n",
            "Epoch 6/25, Loss: 0.000054\n",
            "Epoch 7/25, Loss: 0.000046\n",
            "Epoch 8/25, Loss: 0.000042\n",
            "Epoch 9/25, Loss: 0.000043\n",
            "Epoch 10/25, Loss: 0.000025\n",
            "Epoch 11/25, Loss: 0.000034\n",
            "Epoch 12/25, Loss: 0.000029\n",
            "Epoch 13/25, Loss: 0.000026\n",
            "Epoch 14/25, Loss: 0.000025\n",
            "Epoch 15/25, Loss: 0.000024\n",
            "Epoch 16/25, Loss: 0.000022\n",
            "Epoch 17/25, Loss: 0.000021\n",
            "Epoch 18/25, Loss: 0.000021\n",
            "Epoch 19/25, Loss: 0.000024\n",
            "Epoch 20/25, Loss: 0.000013\n",
            "Epoch 21/25, Loss: 0.000015\n",
            "Epoch 22/25, Loss: 0.000079\n",
            "Epoch 23/25, Loss: 0.000007\n",
            "Epoch 24/25, Loss: 0.000008\n",
            "Epoch 25/25, Loss: 0.000011\n",
            "AUC: 0.7625\n",
            "model_dim: 64  # Hidden unit 크기\n",
            "num_heads: 4  # Attention 헤드 개수\n",
            "ff_layers: 256  # Feed-forward 네트워크 크기\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TranAD 모델 정의\n",
        "class TranADModel(nn.Module):\n",
        "    def __init__(self, input_dim, model_dim, num_heads, num_layers, ff_layers, dropout_rate):\n",
        "        super(TranADModel, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, model_dim)\n",
        "\n",
        "        # Transformer 인코더 레이어\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=model_dim,   # hidden unit의 차원\n",
        "            nhead=num_heads,     # attention 헤드 개수\n",
        "            dim_feedforward=ff_layers,  # Feed-forward 레이어의 크기\n",
        "            dropout=dropout_rate  # Dropout 비율\n",
        "        )\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)  # 여러 층으로 쌓인 encoder\n",
        "\n",
        "        # Output projection (복원된 시계열)\n",
        "        self.output_projection = nn.Linear(model_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_projection(x)\n",
        "        x = self.encoder(x)\n",
        "        x = self.output_projection(x)\n",
        "        return x\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "def load_and_preprocess_data(dataset_path, label_file):\n",
        "    with open(label_file) as f:\n",
        "        label_dict = json.load(f)\n",
        "\n",
        "    data_sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(os.path.join(dataset_path, \"realKnownCause\")):\n",
        "        if not filename.endswith(\".csv\"):\n",
        "            continue\n",
        "\n",
        "        file_path = os.path.join(dataset_path, \"realKnownCause\", filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        values = df[\"value\"].values.astype(float)\n",
        "        timestamps = df[\"timestamp\"].values\n",
        "\n",
        "        min_val, max_val = np.min(values), np.max(values)\n",
        "        scaled_values = (values - min_val) / (max_val - min_val)\n",
        "\n",
        "        label_array = np.zeros_like(scaled_values)\n",
        "        for timestamp in label_dict.get(f\"realKnownCause/{filename}\", []):\n",
        "            timestamp = timestamp.replace(\".000000\", \"\")\n",
        "            indices = np.where(timestamps == timestamp)[0]\n",
        "            for index in indices:\n",
        "                label_array[max(0, index - 4):min(len(label_array), index + 4)] = 1\n",
        "\n",
        "        data_sequences.append(scaled_values)\n",
        "        labels.append(label_array)\n",
        "\n",
        "    return np.concatenate(data_sequences), np.concatenate(labels)\n",
        "\n",
        "# 시계열 윈도우 생성\n",
        "def create_windows(data, labels, window_size):\n",
        "    sequences = []\n",
        "    seq_labels = []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        sequences.append(data[i:i + window_size])\n",
        "        seq_labels.append(labels[i + window_size - 1])\n",
        "\n",
        "    return np.array(sequences), np.array(seq_labels)\n",
        "\n",
        "# 데이터 전처리\n",
        "data, labels = load_and_preprocess_data(dataset_path, label_file)\n",
        "\n",
        "window_size = 10  # 윈도우 크기\n",
        "sequences, seq_labels = create_windows(data, labels, window_size)\n",
        "\n",
        "# Train/Test Split\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(sequences) * split_ratio)\n",
        "\n",
        "train_sequences = torch.tensor(sequences[:split_index], dtype=torch.float32).unsqueeze(-1)\n",
        "train_labels = torch.tensor(seq_labels[:split_index], dtype=torch.float32)\n",
        "\n",
        "test_sequences = torch.tensor(sequences[split_index:], dtype=torch.float32).unsqueeze(-1)\n",
        "test_labels = torch.tensor(seq_labels[split_index:], dtype=torch.float32)\n",
        "\n",
        "train_dataset = TensorDataset(train_sequences, train_labels)\n",
        "test_dataset = TensorDataset(test_sequences, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "\n",
        "# train_data와 test_data의 개수 확인하기\n",
        "train_data_size = train_data.shape[0]\n",
        "test_data_size = test_data.shape[0]\n",
        "\n",
        "print(f\"Train data size: {train_data_size}\")\n",
        "print(f\"Test data size: {test_data_size}\")\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = 1  # 단일 시계열 입력\n",
        "model_dim = 64  # Hidden unit 크기\n",
        "num_heads = 4  # Attention 헤드 개수\n",
        "num_layers = 1  # Transformer Encoder 레이어 수\n",
        "ff_layers = 256  # Feed-forward 네트워크 크기 (2개 레이어를 지정하려면 128 이상을 설정)\n",
        "dropout_rate = 0.1  # Dropout 비율\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "model = TranADModel(input_dim=input_dim, model_dim=model_dim, num_heads=num_heads,\n",
        "                    num_layers=num_layers, ff_layers=ff_layers, dropout_rate=dropout_rate).to(device)\n",
        "\n",
        "# 손실 함수 및 최적화기\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for inputs, _ in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed = model(inputs)\n",
        "        loss = criterion(reconstructed, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * inputs.size(0)\n",
        "    epoch_loss /= len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "# 이상 탐지 평가\n",
        "model.eval()\n",
        "anomaly_scores = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)  # MPS로 이동\n",
        "        reconstructed = model(inputs)\n",
        "        scores = torch.mean((inputs - reconstructed) ** 2, dim=(1, 2)).cpu().numpy()\n",
        "        anomaly_scores.extend(scores)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "\n",
        "# ROC Curve 계산\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, anomaly_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# 최적 임계값 동적 선택 (AUC가 최대가 되는 임계값)\n",
        "optimal_threshold = thresholds[np.argmax(tpr - fpr)]\n",
        "# 예측 결과\n",
        "predicted_labels = (np.array(anomaly_scores) > optimal_threshold).astype(int)\n",
        "\n",
        "# 평가 지표 계산\n",
        "auc_score = roc_auc_score(true_labels, anomaly_scores)\n",
        "\n",
        "# 출력\n",
        "print(\n",
        "    f\"AUC: {auc_score:.4f}\\n\"\n",
        "    f\"model_dim: {model_dim}  # Hidden unit 크기\\n\"\n",
        "    f\"num_heads: {num_heads}  # Attention 헤드 개수\\n\"\n",
        "    f\"ff_layers: {ff_layers}  # Feed-forward 네트워크 크기\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3OceI9utwSz",
        "outputId": "874c0502-e2db-480d-9e1e-8192d46d0ece"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data size: 12665\n",
            "Test data size: 3167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/beenee/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25, Loss: 0.004742\n",
            "Epoch 2/25, Loss: 0.000202\n",
            "Epoch 3/25, Loss: 0.000104\n",
            "Epoch 4/25, Loss: 0.000068\n",
            "Epoch 5/25, Loss: 0.000046\n",
            "Epoch 6/25, Loss: 0.000037\n",
            "Epoch 7/25, Loss: 0.000029\n",
            "Epoch 8/25, Loss: 0.000029\n",
            "Epoch 9/25, Loss: 0.000041\n",
            "Epoch 10/25, Loss: 0.000013\n",
            "Epoch 11/25, Loss: 0.000021\n",
            "Epoch 12/25, Loss: 0.000015\n",
            "Epoch 13/25, Loss: 0.000012\n",
            "Epoch 14/25, Loss: 0.000012\n",
            "Epoch 15/25, Loss: 0.000011\n",
            "Epoch 16/25, Loss: 0.000008\n",
            "Epoch 17/25, Loss: 0.000005\n",
            "Epoch 18/25, Loss: 0.000006\n",
            "Epoch 19/25, Loss: 0.000005\n",
            "Epoch 20/25, Loss: 0.000006\n",
            "Epoch 21/25, Loss: 0.000004\n",
            "Epoch 22/25, Loss: 0.000004\n",
            "Epoch 23/25, Loss: 0.000004\n",
            "Epoch 24/25, Loss: 0.000004\n",
            "Epoch 25/25, Loss: 0.000003\n",
            "AUC: 0.7726\n",
            "model_dim: 36  # Hidden unit 크기\n",
            "num_heads: 6  # Attention 헤드 개수\n",
            "ff_layers: 128  # Feed-forward 네트워크 크기\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TranAD 모델 정의\n",
        "class TranADModel(nn.Module):\n",
        "    def __init__(self, input_dim, model_dim, num_heads, num_layers, ff_layers, dropout_rate):\n",
        "        super(TranADModel, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, model_dim)\n",
        "\n",
        "        # Transformer 인코더 레이어\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=model_dim,   # hidden unit의 차원\n",
        "            nhead=num_heads,     # attention 헤드 개수\n",
        "            dim_feedforward=ff_layers,  # Feed-forward 레이어의 크기\n",
        "            dropout=dropout_rate  # Dropout 비율\n",
        "        )\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)  # 여러 층으로 쌓인 encoder\n",
        "\n",
        "        # Output projection (복원된 시계열)\n",
        "        self.output_projection = nn.Linear(model_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_projection(x)\n",
        "        x = self.encoder(x)\n",
        "        x = self.output_projection(x)\n",
        "        return x\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "def load_and_preprocess_data(dataset_path, label_file):\n",
        "    with open(label_file) as f:\n",
        "        label_dict = json.load(f)\n",
        "\n",
        "    data_sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(os.path.join(dataset_path, \"realKnownCause\")):\n",
        "        if not filename.endswith(\".csv\"):\n",
        "            continue\n",
        "\n",
        "        file_path = os.path.join(dataset_path, \"realKnownCause\", filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        values = df[\"value\"].values.astype(float)\n",
        "        timestamps = df[\"timestamp\"].values\n",
        "\n",
        "        min_val, max_val = np.min(values), np.max(values)\n",
        "        scaled_values = (values - min_val) / (max_val - min_val)\n",
        "\n",
        "        label_array = np.zeros_like(scaled_values)\n",
        "        for timestamp in label_dict.get(f\"realKnownCause/{filename}\", []):\n",
        "            timestamp = timestamp.replace(\".000000\", \"\")\n",
        "            indices = np.where(timestamps == timestamp)[0]\n",
        "            for index in indices:\n",
        "                label_array[max(0, index - 4):min(len(label_array), index + 4)] = 1\n",
        "\n",
        "        data_sequences.append(scaled_values)\n",
        "        labels.append(label_array)\n",
        "\n",
        "    return np.concatenate(data_sequences), np.concatenate(labels)\n",
        "\n",
        "# 시계열 윈도우 생성\n",
        "def create_windows(data, labels, window_size):\n",
        "    sequences = []\n",
        "    seq_labels = []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        sequences.append(data[i:i + window_size])\n",
        "        seq_labels.append(labels[i + window_size - 1])\n",
        "\n",
        "    return np.array(sequences), np.array(seq_labels)\n",
        "\n",
        "# 데이터 전처리\n",
        "data, labels = load_and_preprocess_data(dataset_path, label_file)\n",
        "\n",
        "window_size = 10  # 윈도우 크기\n",
        "sequences, seq_labels = create_windows(data, labels, window_size)\n",
        "\n",
        "# Train/Test Split\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(sequences) * split_ratio)\n",
        "\n",
        "train_sequences = torch.tensor(sequences[:split_index], dtype=torch.float32).unsqueeze(-1)\n",
        "train_labels = torch.tensor(seq_labels[:split_index], dtype=torch.float32)\n",
        "\n",
        "test_sequences = torch.tensor(sequences[split_index:], dtype=torch.float32).unsqueeze(-1)\n",
        "test_labels = torch.tensor(seq_labels[split_index:], dtype=torch.float32)\n",
        "\n",
        "train_dataset = TensorDataset(train_sequences, train_labels)\n",
        "test_dataset = TensorDataset(test_sequences, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "\n",
        "# train_data와 test_data의 개수 확인하기\n",
        "train_data_size = train_data.shape[0]\n",
        "test_data_size = test_data.shape[0]\n",
        "\n",
        "print(f\"Train data size: {train_data_size}\")\n",
        "print(f\"Test data size: {test_data_size}\")\n",
        "\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = 1  # 단일 시계열 입력\n",
        "model_dim = 36  # Hidden unit 크기\n",
        "num_heads = 6  # Attention 헤드 개수\n",
        "num_layers = 1  # Transformer Encoder 레이어 수\n",
        "ff_layers = 128  # Feed-forward 네트워크 크기 (2개 레이어를 지정하려면 128 이상을 설정)\n",
        "dropout_rate = 0.1  # Dropout 비율\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "model = TranADModel(input_dim=input_dim, model_dim=model_dim, num_heads=num_heads,\n",
        "                    num_layers=num_layers, ff_layers=ff_layers, dropout_rate=dropout_rate).to(device)\n",
        "\n",
        "# 손실 함수 및 최적화기\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for inputs, _ in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed = model(inputs)\n",
        "        loss = criterion(reconstructed, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * inputs.size(0)\n",
        "    epoch_loss /= len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "# 이상 탐지 평가\n",
        "model.eval()\n",
        "anomaly_scores = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)  # MPS로 이동\n",
        "        reconstructed = model(inputs)\n",
        "        scores = torch.mean((inputs - reconstructed) ** 2, dim=(1, 2)).cpu().numpy()\n",
        "        anomaly_scores.extend(scores)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "\n",
        "# ROC Curve 계산\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, anomaly_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# 최적 임계값 동적 선택 (AUC가 최대가 되는 임계값)\n",
        "optimal_threshold = thresholds[np.argmax(tpr - fpr)]\n",
        "# 예측 결과\n",
        "predicted_labels = (np.array(anomaly_scores) > optimal_threshold).astype(int)\n",
        "\n",
        "# 평가 지표 계산\n",
        "auc_score = roc_auc_score(true_labels, anomaly_scores)\n",
        "\n",
        "# 출력\n",
        "print(\n",
        "    f\"AUC: {auc_score:.4f}\\n\"\n",
        "    f\"model_dim: {model_dim}  # Hidden unit 크기\\n\"\n",
        "    f\"num_heads: {num_heads}  # Attention 헤드 개수\\n\"\n",
        "    f\"ff_layers: {ff_layers}  # Feed-forward 네트워크 크기\\n\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gX-bkn2NtwS0",
        "outputId": "72e3fcaa-db0e-4776-f774-a8b53b666fd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/beenee/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25, Loss: 0.002081\n",
            "Epoch 2/25, Loss: 0.000156\n",
            "Epoch 3/25, Loss: 0.000084\n",
            "Epoch 4/25, Loss: 0.000058\n",
            "Epoch 5/25, Loss: 0.000048\n",
            "Epoch 6/25, Loss: 0.000035\n",
            "Epoch 7/25, Loss: 0.000028\n",
            "Epoch 8/25, Loss: 0.000024\n",
            "Epoch 9/25, Loss: 0.000017\n",
            "Epoch 10/25, Loss: 0.000017\n",
            "Epoch 11/25, Loss: 0.000014\n",
            "Epoch 12/25, Loss: 0.000013\n",
            "Epoch 13/25, Loss: 0.000007\n",
            "Epoch 14/25, Loss: 0.000008\n",
            "Epoch 15/25, Loss: 0.000007\n",
            "Epoch 16/25, Loss: 0.000006\n",
            "Epoch 17/25, Loss: 0.000007\n",
            "Epoch 18/25, Loss: 0.000004\n",
            "Epoch 19/25, Loss: 0.000004\n",
            "Epoch 20/25, Loss: 0.000003\n",
            "Epoch 21/25, Loss: 0.000003\n",
            "Epoch 22/25, Loss: 0.000003\n",
            "Epoch 23/25, Loss: 0.000003\n",
            "Epoch 24/25, Loss: 0.000002\n",
            "Epoch 25/25, Loss: 0.000003\n",
            "AUC: 0.8436\n"
          ]
        }
      ],
      "source": [
        "# TranAD 모델 정의\n",
        "class TranADModel(nn.Module):\n",
        "    def __init__(self, input_dim, model_dim, num_heads, num_layers, ff_layers, dropout_rate):\n",
        "        super(TranADModel, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, model_dim)\n",
        "\n",
        "        # Transformer 인코더 레이어\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=model_dim,   # hidden unit의 차원\n",
        "            nhead=num_heads,     # attention 헤드 개수\n",
        "            dim_feedforward=ff_layers,  # Feed-forward 레이어의 크기\n",
        "            dropout=dropout_rate  # Dropout 비율\n",
        "        )\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)  # 여러 층으로 쌓인 encoder\n",
        "\n",
        "        # Output projection (복원된 시계열)\n",
        "        self.output_projection = nn.Linear(model_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_projection(x)\n",
        "        x = self.encoder(x)\n",
        "        x = self.output_projection(x)\n",
        "        return x\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "def load_and_preprocess_data(dataset_path, label_file):\n",
        "    with open(label_file) as f:\n",
        "        label_dict = json.load(f)\n",
        "\n",
        "    data_sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(os.path.join(dataset_path, \"realKnownCause\")):\n",
        "        if not filename.endswith(\".csv\"):\n",
        "            continue\n",
        "\n",
        "        file_path = os.path.join(dataset_path, \"realKnownCause\", filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        values = df[\"value\"].values.astype(float)\n",
        "        timestamps = df[\"timestamp\"].values\n",
        "\n",
        "        min_val, max_val = np.min(values), np.max(values)\n",
        "        scaled_values = (values - min_val) / (max_val - min_val)\n",
        "\n",
        "        label_array = np.zeros_like(scaled_values)\n",
        "        for timestamp in label_dict.get(f\"realKnownCause/{filename}\", []):\n",
        "            timestamp = timestamp.replace(\".000000\", \"\")\n",
        "            indices = np.where(timestamps == timestamp)[0]\n",
        "            for index in indices:\n",
        "                label_array[max(0, index - 4):min(len(label_array), index + 4)] = 1\n",
        "\n",
        "        data_sequences.append(scaled_values)\n",
        "        labels.append(label_array)\n",
        "\n",
        "    return np.concatenate(data_sequences), np.concatenate(labels)\n",
        "\n",
        "# 시계열 윈도우 생성\n",
        "def create_windows(data, labels, window_size):\n",
        "    sequences = []\n",
        "    seq_labels = []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        sequences.append(data[i:i + window_size])\n",
        "        seq_labels.append(labels[i + window_size - 1])\n",
        "\n",
        "    return np.array(sequences), np.array(seq_labels)\n",
        "\n",
        "# 데이터 전처리\n",
        "data, labels = load_and_preprocess_data(dataset_path, label_file)\n",
        "\n",
        "window_size = 10  # 윈도우 크기\n",
        "sequences, seq_labels = create_windows(data, labels, window_size)\n",
        "\n",
        "# Train/Test Split\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(sequences) * split_ratio)\n",
        "\n",
        "train_sequences = torch.tensor(sequences[:split_index], dtype=torch.float32).unsqueeze(-1)\n",
        "train_labels = torch.tensor(seq_labels[:split_index], dtype=torch.float32)\n",
        "\n",
        "test_sequences = torch.tensor(sequences[split_index:], dtype=torch.float32).unsqueeze(-1)\n",
        "test_labels = torch.tensor(seq_labels[split_index:], dtype=torch.float32)\n",
        "\n",
        "train_dataset = TensorDataset(train_sequences, train_labels)\n",
        "test_dataset = TensorDataset(test_sequences, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = 1  # 단일 시계열 입력\n",
        "model_dim = 32  # Hidden unit 크기\n",
        "num_heads = 4  # Attention 헤드 개수\n",
        "num_layers = 1  # Transformer Encoder 레이어 수\n",
        "ff_layers = 128  # Feed-forward 네트워크 크기 (2개 레이어를 지정하려면 128 이상을 설정)\n",
        "dropout_rate = 0.1  # Dropout 비율\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "model = TranADModel(input_dim=input_dim, model_dim=model_dim, num_heads=num_heads,\n",
        "                    num_layers=num_layers, ff_layers=ff_layers, dropout_rate=dropout_rate).to(device)\n",
        "\n",
        "# 손실 함수 및 최적화기\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for inputs, _ in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed = model(inputs)\n",
        "        loss = criterion(reconstructed, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * inputs.size(0)\n",
        "    epoch_loss /= len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "# 이상 탐지 평가\n",
        "model.eval()\n",
        "anomaly_scores = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)  # MPS로 이동\n",
        "        reconstructed = model(inputs)\n",
        "        scores = torch.mean((inputs - reconstructed) ** 2, dim=(1, 2)).cpu().numpy()\n",
        "        anomaly_scores.extend(scores)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "\n",
        "# ROC Curve 계산\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, anomaly_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# 최적 임계값 동적 선택 (AUC가 최대가 되는 임계값)\n",
        "optimal_threshold = thresholds[np.argmax(tpr - fpr)]\n",
        "# 예측 결과\n",
        "predicted_labels = (np.array(anomaly_scores) > optimal_threshold).astype(int)\n",
        "\n",
        "# 평가 지표 계산\n",
        "auc_score = roc_auc_score(true_labels, anomaly_scores)\n",
        "\n",
        "print(f\"AUC: {auc_score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRxkkxKwtwS0"
      },
      "source": [
        "## 파라미터 조정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E-t12iPtwS0",
        "outputId": "95aa8fcc-99c6-4249-f5b1-9235520b4c1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/beenee/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25, Loss: 0.003314\n",
            "Epoch 2/25, Loss: 0.000105\n",
            "Epoch 3/25, Loss: 0.000052\n",
            "Epoch 4/25, Loss: 0.000038\n",
            "Epoch 5/25, Loss: 0.000040\n",
            "Epoch 6/25, Loss: 0.000047\n",
            "Epoch 7/25, Loss: 0.000038\n",
            "Epoch 8/25, Loss: 0.000035\n",
            "Epoch 9/25, Loss: 0.000019\n",
            "Epoch 10/25, Loss: 0.000029\n",
            "Epoch 11/25, Loss: 0.000021\n",
            "Epoch 12/25, Loss: 0.000019\n",
            "Epoch 13/25, Loss: 0.000014\n",
            "Epoch 14/25, Loss: 0.000021\n",
            "Epoch 15/25, Loss: 0.000013\n",
            "Epoch 16/25, Loss: 0.000014\n",
            "Epoch 17/25, Loss: 0.000011\n",
            "Epoch 18/25, Loss: 0.000012\n",
            "Epoch 19/25, Loss: 0.000015\n",
            "Epoch 20/25, Loss: 0.000006\n",
            "Epoch 21/25, Loss: 0.000009\n",
            "Epoch 22/25, Loss: 0.000010\n",
            "Epoch 23/25, Loss: 0.000006\n",
            "Epoch 24/25, Loss: 0.000042\n",
            "Epoch 25/25, Loss: 0.000004\n",
            "AUC: 0.8534\n",
            "model_dim: 66  # Hidden unit 크기\n",
            "num_heads: 6  # Attention 헤드 개수\n",
            "ff_layers: 256  # Feed-forward 네트워크 크기\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TranAD 모델 정의\n",
        "class TranADModel(nn.Module):\n",
        "    def __init__(self, input_dim, model_dim, num_heads, num_layers, ff_layers, dropout_rate):\n",
        "        super(TranADModel, self).__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, model_dim)\n",
        "\n",
        "        # Transformer 인코더 레이어\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=model_dim,   # hidden unit의 차원\n",
        "            nhead=num_heads,     # attention 헤드 개수\n",
        "            dim_feedforward=ff_layers,  # Feed-forward 레이어의 크기\n",
        "            dropout=dropout_rate  # Dropout 비율\n",
        "        )\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)  # 여러 층으로 쌓인 encoder\n",
        "\n",
        "        # Output projection (복원된 시계열)\n",
        "        self.output_projection = nn.Linear(model_dim, input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_projection(x)\n",
        "        x = self.encoder(x)\n",
        "        x = self.output_projection(x)\n",
        "        return x\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "def load_and_preprocess_data(dataset_path, label_file):\n",
        "    with open(label_file) as f:\n",
        "        label_dict = json.load(f)\n",
        "\n",
        "    data_sequences = []\n",
        "    labels = []\n",
        "\n",
        "    for filename in os.listdir(os.path.join(dataset_path, \"realKnownCause\")):\n",
        "        if not filename.endswith(\".csv\"):\n",
        "            continue\n",
        "\n",
        "        file_path = os.path.join(dataset_path, \"realKnownCause\", filename)\n",
        "        df = pd.read_csv(file_path)\n",
        "\n",
        "        values = df[\"value\"].values.astype(float)\n",
        "        timestamps = df[\"timestamp\"].values\n",
        "\n",
        "        min_val, max_val = np.min(values), np.max(values)\n",
        "        scaled_values = (values - min_val) / (max_val - min_val)\n",
        "\n",
        "        label_array = np.zeros_like(scaled_values)\n",
        "        for timestamp in label_dict.get(f\"realKnownCause/{filename}\", []):\n",
        "            timestamp = timestamp.replace(\".000000\", \"\")\n",
        "            indices = np.where(timestamps == timestamp)[0]\n",
        "            for index in indices:\n",
        "                label_array[max(0, index - 4):min(len(label_array), index + 4)] = 1\n",
        "\n",
        "        data_sequences.append(scaled_values)\n",
        "        labels.append(label_array)\n",
        "\n",
        "    return np.concatenate(data_sequences), np.concatenate(labels)\n",
        "\n",
        "# 시계열 윈도우 생성\n",
        "def create_windows(data, labels, window_size):\n",
        "    sequences = []\n",
        "    seq_labels = []\n",
        "\n",
        "    for i in range(len(data) - window_size):\n",
        "        sequences.append(data[i:i + window_size])\n",
        "        seq_labels.append(labels[i + window_size - 1])\n",
        "\n",
        "    return np.array(sequences), np.array(seq_labels)\n",
        "\n",
        "# 데이터 전처리\n",
        "data, labels = load_and_preprocess_data(dataset_path, label_file)\n",
        "\n",
        "window_size = 10  # 윈도우 크기\n",
        "sequences, seq_labels = create_windows(data, labels, window_size)\n",
        "\n",
        "# Train/Test Split\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(sequences) * split_ratio)\n",
        "\n",
        "train_sequences = torch.tensor(sequences[:split_index], dtype=torch.float32).unsqueeze(-1)\n",
        "train_labels = torch.tensor(seq_labels[:split_index], dtype=torch.float32)\n",
        "\n",
        "test_sequences = torch.tensor(sequences[split_index:], dtype=torch.float32).unsqueeze(-1)\n",
        "test_labels = torch.tensor(seq_labels[split_index:], dtype=torch.float32)\n",
        "\n",
        "train_dataset = TensorDataset(train_sequences, train_labels)\n",
        "test_dataset = TensorDataset(test_sequences, test_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64)\n",
        "\n",
        "# 모델 초기화\n",
        "input_dim = 1  # 단일 시계열 입력\n",
        "model_dim = 66  # Hidden unit 크기\n",
        "num_heads = 6  # Attention 헤드 개수\n",
        "num_layers = 1  # Transformer Encoder 레이어 수\n",
        "ff_layers = 256  # Feed-forward 네트워크 크기 (2개 레이어를 지정하려면 128 이상을 설정)\n",
        "dropout_rate = 0.1  # Dropout 비율\n",
        "\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "model = TranADModel(input_dim=input_dim, model_dim=model_dim, num_heads=num_heads,\n",
        "                    num_layers=num_layers, ff_layers=ff_layers, dropout_rate=dropout_rate).to(device)\n",
        "\n",
        "# 손실 함수 및 최적화기\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 학습 루프\n",
        "num_epochs = 25\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    for inputs, _ in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        reconstructed = model(inputs)\n",
        "        loss = criterion(reconstructed, inputs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item() * inputs.size(0)\n",
        "    epoch_loss /= len(train_loader.dataset)\n",
        "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.6f}\")\n",
        "\n",
        "# 이상 탐지 평가\n",
        "model.eval()\n",
        "anomaly_scores = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)  # MPS로 이동\n",
        "        reconstructed = model(inputs)\n",
        "        scores = torch.mean((inputs - reconstructed) ** 2, dim=(1, 2)).cpu().numpy()\n",
        "        anomaly_scores.extend(scores)\n",
        "        true_labels.extend(labels.numpy())\n",
        "\n",
        "\n",
        "# ROC Curve 계산\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, anomaly_scores)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# 최적 임계값 동적 선택 (AUC가 최대가 되는 임계값)\n",
        "optimal_threshold = thresholds[np.argmax(tpr - fpr)]\n",
        "# 예측 결과\n",
        "predicted_labels = (np.array(anomaly_scores) > optimal_threshold).astype(int)\n",
        "\n",
        "# 평가 지표 계산\n",
        "auc_score = roc_auc_score(true_labels, anomaly_scores)\n",
        "\n",
        "# 출력\n",
        "print(\n",
        "    f\"AUC: {auc_score:.4f}\\n\"\n",
        "    f\"model_dim: {model_dim}  # Hidden unit 크기\\n\"\n",
        "    f\"num_heads: {num_heads}  # Attention 헤드 개수\\n\"\n",
        "    f\"ff_layers: {ff_layers}  # Feed-forward 네트워크 크기\\n\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M57Wa5PtwS1",
        "outputId": "ced0c030-a545-48e3-d5c0-f18ef3ddb84f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAB dataset processed and saved in /Users/beenee/Downloads/NAB.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# 데이터 폴더 및 출력 폴더 경로 설정\n",
        "data_folder = \"/Users/beenee/Downloads\"  # 데이터셋이 저장된 기본 폴더\n",
        "output_folder = \"/Users/beenee/Downloads\"  # 전처리된 결과를 저장할 폴더\n",
        "\n",
        "def normalize3(a, min_a=None, max_a=None):\n",
        "    \"\"\"\n",
        "    데이터 정규화 함수\n",
        "    \"\"\"\n",
        "    if min_a is None:\n",
        "        min_a, max_a = np.min(a, axis=0), np.max(a, axis=0)\n",
        "    return (a - min_a) / (max_a - min_a + 1e-4), min_a, max_a\n",
        "\n",
        "def load_data(dataset):\n",
        "    \"\"\"\n",
        "    NAB 데이터셋만 처리하는 함수\n",
        "    \"\"\"\n",
        "    folder = os.path.join(output_folder, dataset)\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    if dataset == 'NAB':\n",
        "        dataset_folder = os.path.join(data_folder, 'NAB')\n",
        "        file_list = os.listdir(dataset_folder)\n",
        "\n",
        "        # JSON 파일에서 라벨 정보 로드\n",
        "        with open(os.path.join(dataset_folder, 'labels.json')) as f:\n",
        "            labeldict = json.load(f)\n",
        "\n",
        "        for filename in file_list:\n",
        "            if not filename.endswith('.csv'):\n",
        "                continue\n",
        "\n",
        "            # 데이터 로드\n",
        "            df = pd.read_csv(os.path.join(dataset_folder, filename))\n",
        "            vals = df.values[:, 1]  # 시계열 값\n",
        "            labels = np.zeros_like(vals, dtype=np.float64)\n",
        "\n",
        "            # 이상 탐지 구간 라벨 설정\n",
        "            for timestamp in labeldict.get(f\"realKnownCause/{filename}\", []):\n",
        "                tstamp = timestamp.replace('.000000', '')\n",
        "                index = np.where(((df['timestamp'] == tstamp).values + 0) == 1)[0][0]\n",
        "                labels[index - 4:index + 4] = 1\n",
        "\n",
        "            # 데이터 정규화\n",
        "            min_temp, max_temp = np.min(vals), np.max(vals)\n",
        "            vals = (vals - min_temp) / (max_temp - min_temp)\n",
        "            train, test = vals.astype(float), vals.astype(float)\n",
        "            train, test, labels = train.reshape(-1, 1), test.reshape(-1, 1), labels.reshape(-1, 1)\n",
        "\n",
        "            # 파일 저장\n",
        "            fn = filename.replace('.csv', '')\n",
        "            for file, data in zip(['train', 'test', 'labels'], [train, test, labels]):\n",
        "                np.save(os.path.join(folder, f'{fn}_{file}.npy'), data)\n",
        "        print(f\"NAB dataset processed and saved in {folder}.\")\n",
        "    else:\n",
        "        raise Exception(f\"Dataset {dataset} not supported.\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # NAB 데이터셋 처리\n",
        "    dataset = 'NAB'\n",
        "    load_data(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tck8xHcvtwS1",
        "outputId": "5e5b712b-fdaa-4b74-c97a-d9570b137fbd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-07-04 00:00:00</td>\n",
              "      <td>69.880835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-07-04 01:00:00</td>\n",
              "      <td>71.220227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-07-04 02:00:00</td>\n",
              "      <td>70.877805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-07-04 03:00:00</td>\n",
              "      <td>68.959400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-07-04 04:00:00</td>\n",
              "      <td>69.283551</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            timestamp      value\n",
              "0 2013-07-04 00:00:00  69.880835\n",
              "1 2013-07-04 01:00:00  71.220227\n",
              "2 2013-07-04 02:00:00  70.877805\n",
              "3 2013-07-04 03:00:00  68.959400\n",
              "4 2013-07-04 04:00:00  69.283551"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터 파일 경로 설정\n",
        "data_folder = '/Users/beenee/Downloads/realKnownCause'\n",
        "\n",
        "# NAB 데이터셋과 레이블 불러오기\n",
        "def load_data():\n",
        "    # 데이터셋 파일 이름 (예시)\n",
        "    data_files = [f for f in os.listdir(data_folder) if f.endswith('.csv')]\n",
        "    label_file = 'labels.json'\n",
        "\n",
        "    # 데이터를 담을 리스트\n",
        "    data_list = []\n",
        "\n",
        "    # 각 CSV 파일을 읽고 데이터를 합침\n",
        "    for data_file in data_files:\n",
        "        data_path = os.path.join(data_folder, data_file)\n",
        "        data = pd.read_csv(data_path)\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "        data_list.append(data)\n",
        "\n",
        "    # 레이블 파일 불러오기\n",
        "    with open(os.path.join(data_folder, label_file), 'r') as f:\n",
        "        labels = json.load(f)\n",
        "\n",
        "    return data_list, labels\n",
        "\n",
        "# 데이터와 레이블 불러오기\n",
        "data_list, labels = load_data()\n",
        "\n",
        "# 첫 번째 데이터셋 확인\n",
        "data_list[0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QucOj-VBtwS1",
        "outputId": "f342ee4d-2326-4f68-a1dd-907d4540c8f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>value</th>\n",
              "      <th>scaled_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2013-07-04 00:00:00</td>\n",
              "      <td>69.880835</td>\n",
              "      <td>-0.320586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2013-07-04 01:00:00</td>\n",
              "      <td>71.220227</td>\n",
              "      <td>-0.005228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2013-07-04 02:00:00</td>\n",
              "      <td>70.877805</td>\n",
              "      <td>-0.085851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2013-07-04 03:00:00</td>\n",
              "      <td>68.959400</td>\n",
              "      <td>-0.537536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2013-07-04 04:00:00</td>\n",
              "      <td>69.283551</td>\n",
              "      <td>-0.461215</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            timestamp      value  scaled_value\n",
              "0 2013-07-04 00:00:00  69.880835     -0.320586\n",
              "1 2013-07-04 01:00:00  71.220227     -0.005228\n",
              "2 2013-07-04 02:00:00  70.877805     -0.085851\n",
              "3 2013-07-04 03:00:00  68.959400     -0.537536\n",
              "4 2013-07-04 04:00:00  69.283551     -0.461215"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 데이터 전처리 함수\n",
        "def preprocess_data(data):\n",
        "    # 예시: 결측치 처리, 스케일링\n",
        "    data = data.dropna()  # 결측치 제거\n",
        "    scaler = StandardScaler()\n",
        "    data_scaled = scaler.fit_transform(data[['value']])  # value 컬럼만 스케일링\n",
        "    data['scaled_value'] = data_scaled\n",
        "    return data\n",
        "\n",
        "# 전처리된 데이터 리스트 생성\n",
        "preprocessed_data_list = [preprocess_data(data) for data in data_list]\n",
        "\n",
        "# 전처리된 데이터 중 첫 번째 데이터셋 확인\n",
        "preprocessed_data_list[0].head()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}